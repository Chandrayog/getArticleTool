{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ongoing-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path at terminal when executing this file\n",
      "/Users/chandra/Documents/localBranch\n",
      "\n",
      "Enter search engine number to lookup your article from list, input multiple numbers with space only:\n",
      " 0 ALL, 1 Google Scholar, 2 MS Academic, 3 CORE, 4 PubMed, 5 ACM Library, 6 PLOS ONE, 7 Academia, 8 Elsevier Scopus, 9 Springer, 10 Science Direct\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a Search Engine value:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to save the JSON output file or enter to save on default location:\n",
      " E.g. (/Users/computername/Desktop/) \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Path: \n",
      "Do you also want Excel output? Y/N : \n",
      "Do you also want Logging? Y/N : \n",
      "Enter No of records to search(Minimum 10 or press enter): \n",
      "Enter the FROM year (optional): \n",
      "Enter the TO year (optional): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose either Title, Keyword, or Abstract Info as options to search:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Keyword to search (if not then press enter to go to next option): python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching in PubMed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with total 12 records returned.\n",
      "[{'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1364/AO.58.000D98.      ', 'Title': 'Burmese python target reflectivity compared to natural Florida foliage background reflectivity', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31044871/', 'Authors': ['No information found', 'Ronald Driggers', 'Orges Furxhi', 'Gonzalo Vaca', 'Veerle Reumers', 'Milad Vazimali', 'Robert Short', 'Prashant Agrawal', 'Andy Lambrechts', 'Wouter Charle', 'Kathleen Vunckx', 'Carl Arvidson'], 'Publication Name': 'Copyright © 2019 Elsevier Ltd. All rights reserved.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Veterinary Clinic of Auteuil Village, 35 rue Leconte de Lisle, 75016 Paris, France.', 'Type': \"['article']\", 'Published date': ' 2019 Jun 29.      ', 'Abstract': 'The Florida Everglades is infested with Burmese pythons caused by the release of exotic pets in the 1980s. The current estimates are between 30,000 and 300,000 pythons, where the result is a severe decline in Everglade mammals: 90% reductions in raccoon, opossum, bobcats, and foxes. The marsh rabbits are completely gone. The population of the pythons is rapidly increasing exponentially with 20-50 eggs per snake with a life span of up to 20 years. Pythons have been captured in the Everglades with lengths of nearly 6 m. Researchers in the state of Florida are concerned that these pythons are (1) permanently damaging the Everglades, (2) migrating further north into populated areas of Florida, and (3) endangering wildlife, pets, and eventually, people. There have been a number of sensing efforts attempted in the large-area detection of pythons, where limited success has been achieved. For example, infrared sensors have been applied to the problem, but the pythons are cold-blooded, so the infrared bands do not work well. Imec has leveraged its expertise and infrastructure in semiconductor processing to produce highly compact, higher performance, and relatively cheaper hyperspectral image sensors and camera systems. In this work, Imec teamed with the University of Florida and Extended Reality Systems to obtain hyperspectral reflectivity measurements of Burmese pythons along with natural Florida background foliage to determine bands or band combinations that may be exploited in the large-area detection of pythons. The bands investigated are the visible-near infrared (or VisNIR) and the shortwave infrared (SWIR) bands. The results show that there are enough differences in the data collection such that a single band, inexpensive VisNIR band camera may provide reasonable results and a two-band, VisNIR/SWIR combination may provide higher performance results. In this paper, we provide the VisNIR results.'}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1364/AO.58.000D98.      ', 'Title': 'Burmese python target reflectivity compared to natural Florida foliage background reflectivity', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31044871/', 'Authors': ['No information found', 'Ronald Driggers', 'Orges Furxhi', 'Gonzalo Vaca', 'Veerle Reumers', 'Milad Vazimali', 'Robert Short', 'Prashant Agrawal', 'Andy Lambrechts', 'Wouter Charle', 'Kathleen Vunckx', 'Carl Arvidson'], 'Publication Name': 'Copyright © 2019 Elsevier Ltd. All rights reserved.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Veterinary Clinic of Auteuil Village, 35 rue Leconte de Lisle, 75016 Paris, France.', 'Type': \"['article']\", 'Published date': ' 2019 Jun 29.      ', 'Abstract': 'The Florida Everglades is infested with Burmese pythons caused by the release of exotic pets in the 1980s. The current estimates are between 30,000 and 300,000 pythons, where the result is a severe decline in Everglade mammals: 90% reductions in raccoon, opossum, bobcats, and foxes. The marsh rabbits are completely gone. The population of the pythons is rapidly increasing exponentially with 20-50 eggs per snake with a life span of up to 20 years. Pythons have been captured in the Everglades with lengths of nearly 6 m. Researchers in the state of Florida are concerned that these pythons are (1) permanently damaging the Everglades, (2) migrating further north into populated areas of Florida, and (3) endangering wildlife, pets, and eventually, people. There have been a number of sensing efforts attempted in the large-area detection of pythons, where limited success has been achieved. For example, infrared sensors have been applied to the problem, but the pythons are cold-blooded, so the infrared bands do not work well. Imec has leveraged its expertise and infrastructure in semiconductor processing to produce highly compact, higher performance, and relatively cheaper hyperspectral image sensors and camera systems. In this work, Imec teamed with the University of Florida and Extended Reality Systems to obtain hyperspectral reflectivity measurements of Burmese pythons along with natural Florida background foliage to determine bands or band combinations that may be exploited in the large-area detection of pythons. The bands investigated are the visible-near infrared (or VisNIR) and the shortwave infrared (SWIR) bands. The results show that there are enough differences in the data collection such that a single band, inexpensive VisNIR band camera may provide reasonable results and a two-band, VisNIR/SWIR combination may provide higher performance results. In this paper, we provide the VisNIR results.'}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1364/AO.58.000D98.      ', 'Title': 'Burmese python target reflectivity compared to natural Florida foliage background reflectivity', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31044871/', 'Authors': ['No information found', 'Ronald Driggers', 'Orges Furxhi', 'Gonzalo Vaca', 'Veerle Reumers', 'Milad Vazimali', 'Robert Short', 'Prashant Agrawal', 'Andy Lambrechts', 'Wouter Charle', 'Kathleen Vunckx', 'Carl Arvidson', 'Ronald Driggers', 'Orges Furxhi', 'Gonzalo Vaca', 'Veerle Reumers', 'Milad Vazimali', 'Robert Short', 'Prashant Agrawal', 'Andy Lambrechts', 'Wouter Charle', 'Kathleen Vunckx', 'Carl Arvidson'], 'Publication Name': 'Copyright © 2019 Elsevier Ltd. All rights reserved.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Veterinary Clinic of Auteuil Village, 35 rue Leconte de Lisle, 75016 Paris, France.', 'Type': \"['article']\", 'Published date': ' 2019 Jun 29.      ', 'Abstract': 'The Florida Everglades is infested with Burmese pythons caused by the release of exotic pets in the 1980s. The current estimates are between 30,000 and 300,000 pythons, where the result is a severe decline in Everglade mammals: 90% reductions in raccoon, opossum, bobcats, and foxes. The marsh rabbits are completely gone. The population of the pythons is rapidly increasing exponentially with 20-50 eggs per snake with a life span of up to 20 years. Pythons have been captured in the Everglades with lengths of nearly 6 m. Researchers in the state of Florida are concerned that these pythons are (1) permanently damaging the Everglades, (2) migrating further north into populated areas of Florida, and (3) endangering wildlife, pets, and eventually, people. There have been a number of sensing efforts attempted in the large-area detection of pythons, where limited success has been achieved. For example, infrared sensors have been applied to the problem, but the pythons are cold-blooded, so the infrared bands do not work well. Imec has leveraged its expertise and infrastructure in semiconductor processing to produce highly compact, higher performance, and relatively cheaper hyperspectral image sensors and camera systems. In this work, Imec teamed with the University of Florida and Extended Reality Systems to obtain hyperspectral reflectivity measurements of Burmese pythons along with natural Florida background foliage to determine bands or band combinations that may be exploited in the large-area detection of pythons. The bands investigated are the visible-near infrared (or VisNIR) and the shortwave infrared (SWIR) bands. The results show that there are enough differences in the data collection such that a single band, inexpensive VisNIR band camera may provide reasonable results and a two-band, VisNIR/SWIR combination may provide higher performance results. In this paper, we provide the VisNIR results.'}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1364/AO.58.000D98.      ', 'Title': 'Burmese python target reflectivity compared to natural Florida foliage background reflectivity', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31044871/', 'Authors': ['No information found', 'Ronald Driggers', 'Orges Furxhi', 'Gonzalo Vaca', 'Veerle Reumers', 'Milad Vazimali', 'Robert Short', 'Prashant Agrawal', 'Andy Lambrechts', 'Wouter Charle', 'Kathleen Vunckx', 'Carl Arvidson', 'Ronald Driggers', 'Orges Furxhi', 'Gonzalo Vaca', 'Veerle Reumers', 'Milad Vazimali', 'Robert Short', 'Prashant Agrawal', 'Andy Lambrechts', 'Wouter Charle', 'Kathleen Vunckx', 'Carl Arvidson'], 'Publication Name': 'Copyright © 2019 Elsevier Ltd. All rights reserved.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Veterinary Clinic of Auteuil Village, 35 rue Leconte de Lisle, 75016 Paris, France.', 'Type': \"['article']\", 'Published date': ' 2019 Jun 29.      ', 'Abstract': 'The Florida Everglades is infested with Burmese pythons caused by the release of exotic pets in the 1980s. The current estimates are between 30,000 and 300,000 pythons, where the result is a severe decline in Everglade mammals: 90% reductions in raccoon, opossum, bobcats, and foxes. The marsh rabbits are completely gone. The population of the pythons is rapidly increasing exponentially with 20-50 eggs per snake with a life span of up to 20 years. Pythons have been captured in the Everglades with lengths of nearly 6 m. Researchers in the state of Florida are concerned that these pythons are (1) permanently damaging the Everglades, (2) migrating further north into populated areas of Florida, and (3) endangering wildlife, pets, and eventually, people. There have been a number of sensing efforts attempted in the large-area detection of pythons, where limited success has been achieved. For example, infrared sensors have been applied to the problem, but the pythons are cold-blooded, so the infrared bands do not work well. Imec has leveraged its expertise and infrastructure in semiconductor processing to produce highly compact, higher performance, and relatively cheaper hyperspectral image sensors and camera systems. In this work, Imec teamed with the University of Florida and Extended Reality Systems to obtain hyperspectral reflectivity measurements of Burmese pythons along with natural Florida background foliage to determine bands or band combinations that may be exploited in the large-area detection of pythons. The bands investigated are the visible-near infrared (or VisNIR) and the shortwave infrared (SWIR) bands. The results show that there are enough differences in the data collection such that a single band, inexpensive VisNIR band camera may provide reasonable results and a two-band, VisNIR/SWIR combination may provide higher performance results. In this paper, we provide the VisNIR results.'}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1638/2019-0032.      ', 'Title': 'TWO-DIMENSIONAL ECHOCARDIOGRAPHIC MEASUREMENTS IN THE BALL PYTHON ( PYTHON REGIUS)', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31926531/', 'Authors': ['No information found', 'Clément Paillusseau', '1', 'Frédéric Gandar', '1', 'Lionel Schilliger', '2', 'Valérie Chetboul', '3', '4'], 'Publication Name': ['No information found'], 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Veterinary Clinic of Auteuil Village, 35 rue Leconte de Lisle, 75016 Paris, France.', 'Type': \"['article']\", 'Published date': ['No information found'], 'Abstract': 'Reptiles can suffer from infectious and noninfectious cardiac pathologies, requiring the need for standardized diagnostic approaches and reference intervals. Despite the popularity of ball pythons (Python regius) as pets, echocardiographic measurements are unknown in this species. Twenty healthy adult ball pythons were evaluated to identify imaging planes, establish reference intervals for cardiac assessment by two-dimensional echocardiography, and study the effects of sex, body length, and body mass on heart rate, fractional shortening, and vascular, atrial, and ventricular dimensions. Echocardiography was performed under manual restraint. Most cardiac measurements were positively correlated with body length and mass, with the strongest correlation between ventricular end-systolic measurements and body length. The only significant difference found between sexes was for right and left atrial lengths. This study provides guidelines and reference intervals for two-dimensional echocardiographic measurements in adult healthy ball pythons.'}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1007/s00128-019-02670-6.      ', 'Title': 'Mercury Concentrations in Invasive Burmese Pythons (Python bivitattus) of Southwest Florida', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31256202/', 'Authors': ['No information found', 'Darren G Rumbold', '1', 'Ian A Bartoszek', '2'], 'Publication Name': ['No information found'], 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Florida Gulf Coast University, 0501 FGCU Blvd. South, Fort Myers, FL, 33965, USA. drumbold@fgcu.edu.', 'Type': \"['article']\", 'Published date': ' 2019 Jun 29.      ', 'Abstract': 'We determined mercury (Hg) concentrations in various tissues of Burmese pythons (Python bivitattus; n = 227) caught in southwest Florida from 2012-2018 as part of a program to control this invasive species. Mercury ranged as high as 4.86 mg/kg in liver tissue from a snake that was 4.7 m long but overall averaged 0.12 ± 0.19 mg/kg in tail tips (n = 123). These levels were relatively low as compared to concentrations reported in pythons from Everglades National Park, a recognized Hg hotspot. These results show that snakes, particularly watersnakes, present another opportunity to biomonitor Hg at the aquatic-terrestrial interface. Although capturing snakes presents obvious challenges, which differ from sampling other taxa typically used in monitoring programs, taking advantage of this program to control an invasive species was cost effective and alleviated concerns about sampling and possibly reducing native snake populations.'}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1556/004.2019.014.      ', 'Title': 'First molecular detection of ball python nidovirus in Italy - Short communication', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/30922084/', 'Authors': ['No information found', 'Elisa Rampacci', '1', 'Marco Masi', '2', 'Francesco Carlo Origgi', '3', 'Valentina Stefanetti', '1', 'Marco Bottinelli', '1', 'Paolo Selleri', '2', 'Mauro Coletti', '1', 'Fabrizio Passamonti', '1'], 'Publication Name': ['No information found'], 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 1 Department of Veterinary Medicine, University of Perugia , San Costanzo 4, 06126, Perugia , Italy.', 'Type': \"['article']\", 'Published date': ['No information found'], 'Abstract': \"A retrospective study was conducted to investigate the presence of ferlavirus, ball python nidovirus and bacteria in 32 tracheobronchial lavages from ball pythons raised in captivity and affected by respiratory disease. A touchdown reverse transcription polymerase reaction (RT-PCR) was performed to detect ball python nidovirus RNA targeting a 260-bp portion of the ORF1a gene, while a nested RT-PCR was applied to identify RNA targeting the 518-bp ferlavirus partial L gene. RT-PCR positive products were submitted for Sanger's sequencing and phylogeny reconstruction. Bacteriological examinations were performed to diagnose a possible bacterial involvement. BLAST analysis revealed that the nucleotide sequences of the six (18.8%) RT-PCR positive amplicons were 90-97% identical to the partial sequence of the ORF1a gene of the recently described ball python nidovirus. All tested snakes were negative for ferlavirus. Thirteen out of 32 samples (40.6%) were bacteriologically positive. Respiratory tract diseases can be a substantial problem for snake breeders, considering the rapid transmission of respiratory pathogens. The results and published studies show that ball python nidovirus is circulating in python collections and could be linked to suboptimal management practices. Surveillance programs are desirable as part of the routine snake health assessment. Tracheobronchial lavage is a fast, practical, cost-effective procedure for sample collection.\"}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1016/j.jcpa.2019.10.007.      ', 'Title': 'A Branchial Cyst in a Diamond Python (Morelia spilota)', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31812178/', 'Authors': ['No information found', 'E Cloup', '1', 'C Thomas', '2', 'J E Cooper', '3'], 'Publication Name': 'Copyright © 2019 Elsevier Ltd. All rights reserved.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': \"1 Department of Veterinary Medicine, The Queen's Veterinary School Hospital, University of Cambridge, Cambridge, UK. Electronic address: em.cloup@gmail.com.\", 'Type': \"['article']\", 'Published date': ' 2019 Nov 20.      ', 'Abstract': 'A 9-year-old female diamond python (Morelia spilota) was presented with a submandibular swelling. The cytological, macroscopic and histological features of this lesion indicated a diagnosis of branchial (pharyngeal) cyst. Branchial cysts are benign lesions caused by anomalous development of the branchial apparatus and are described rarely in veterinary medicine. We suggest that possible persistence of branchial remnants should be included in the consideration of differential diagnoses for neck masses in adult snakes.'}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1016/j.ygcen.2019.113374.      ', 'Title': 'Fear-based aggression and its relationship to corticosterone responsiveness in three species of python', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31891687/', 'Authors': ['No information found', 'J Alex Brashears', '1', 'H Bobby Fokidis', '2', 'Dale F DeNardo', '3'], 'Publication Name': 'Copyright © 2019 Elsevier Inc. All rights reserved.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 School of Life Sciences, Arizona State University, Tempe, AZ, USA. Electronic address: jbrashears@lagcc.cuny.edu.', 'Type': \"['article']\", 'Published date': ' 2019 Dec 28.      ', 'Abstract': \"It has long been known that even closely related species can vary in their antipredator behavior, and in the last two decades there has been mounting interest in how these differences might relate to the hormonal stress response. We tested the relationship between fear-based aggression, a form of antipredator behavior, and plasma corticosterone levels in three species of python [Children's Python (Antaresia childreni), Ball Python (Python regius), Bismarck Ring Python (Bothrochilus boa)]. We recorded the amount of striking in response to perturbation before and after a controlled, stressful confinement. We also measured plasma corticosterone levels prior to confinement, after confinement, and after confinement plus an adrenocorticotropin hormone (ACTH) injection, the later to induce a maximal corticosterone response. We performed among species analyses using two mixed models, and we determined between individual variance within each species to estimate repeatability. Bismarck Ring Pythons struck more than either Ball Pythons or Children's Pythons, and Ball Pythons had a suppressed corticosterone response compared to Children's and Bismarck Ring Pythons. Thus, mean species fear-based aggression correlated with species level differences in corticosterone profile. We also found evidence suggesting behaviors are repeatable within individuals. Our results point to a need for further exploration of aggression, anti-predator behavior, and corticosterone profile.\"}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1242/jeb.173377.      ', 'Title': 'Food consumption increases cell proliferation in the python brain', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/29496780/', 'Authors': ['No information found', 'Stacy S Habroun', '1', '2', 'Andrew A Schaffner', '3', 'Emily N Taylor', '1', 'Christine R Strand', '4'], 'Publication Name': '© 2018. Published by The Company of Biologists Ltd.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Biological Sciences Department, California Polytechnic State University, San Luis Obispo, CA 93407-0401, USA.', 'Type': \"['article']\", 'Published date': ['No information found'], 'Abstract': \"Pythons are model organisms for investigating physiological responses to food intake. While systemic growth in response to food consumption is well documented, what occurs in the brain is currently unexplored. In this study, male ball pythons (Python regius) were used to test the hypothesis that food consumption stimulates cell proliferation in the brain. We used 5-bromo-12'-deoxyuridine (BrdU) as a cell-birth marker to quantify and compare cell proliferation in the brain of fasted snakes and those at 2 and 6 days after a meal. Throughout the telencephalon, cell proliferation was significantly increased in the 6 day group, with no difference between the 2 day group and controls. Systemic postprandial plasticity occurs quickly after a meal is ingested, during the period of active digestion; however, the brain displays a surge of cell proliferation after most digestion and absorption is complete.\"}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1016/j.cbpa.2019.110620.      ', 'Title': 'Endothelin-1 induces a strong pressor effect in ball pythons (Python regius)', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/31770594/', 'Authors': ['No information found', 'Maja Fuhlendorff Jensen', '1', 'Signe Nedergaard', '2', 'Hang Nguyen Nielsen', '3', 'Nini Skovgaard', '4', 'Tinna V Stevnsner', '5', 'Tobias Wang', '6'], 'Publication Name': 'Copyright © 2019 Elsevier Inc. All rights reserved.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Zoophysiology, Department of Bioscience, Aarhus University, 8000 Aarhus, Denmark; Department of Molecular Biology and Genetics, Aarhus University, 8000 Aarhus, Denmark. Electronic address: maja.fuhlendorff@clin.au.dk.', 'Type': \"['article']\", 'Published date': ' 2019 Nov 23.      ', 'Abstract': 'Endothelin-1 (ET-1) is a very potent vasoactive peptide released from endothelial cells, and ET-1 plays an important role in the maintenance and regulation of blood pressure in mammals. ET-1 signaling is mediated by two receptors: ETA and ETB. In mammals, ETA receptors are located on vascular smooth muscle where they mediate vasoconstriction. ETB receptors located on the endothelium mediate vasodilatation through the release of nitric oxide, whereas stimulation of ETB receptors placed on vascular smooth muscle leads to vasoconstriction. Less is known about ET-1 signaling in reptiles. In anaesthetized alligators, ET-1 elicits a biphasic blood pressure with a long-lasting initial decrease followed by a smaller increase in systemic blood pressure. In anaesthetized freshwater turtles, ET-1 causes a dose-dependent systemic vasodilatation mediated through ETB receptors. In the present study, we investigated the cardiovascular effects of ET-1 on the systemic and pulmonary vasculature of pythons. The presence of ETA and ETB receptors in the vasculature of pythons was verified by means of immunoblotting. Myography on isolated vessels revealed a dose-dependent vasoconstrictory response to ET-1 in both mesenteric and pulmonary arteries. Pressure measurements in recovered specimens revealed an ET-1-induced rise in systemic blood pressure supporting our in vitro findings. In conclusion, our study shows that ET-1 induces a strong pressor effect in the systemic circulation.'}]}}, {'entities': {'Search Engine': 'PubMed Engine', 'Attributes found': 'DOI,Title, URLs, Authors,Type, Published Date,Publication Name,Affiliation, Abstract', 'items': [{'DOI': ': 10.1093/gigascience/gix057.      ', 'Title': 'Transcriptome analysis of the response of Burmese python to digestion', 'URLs': 'https://pubmed.ncbi.nlm.nih.gov/28873961/', 'Authors': ['No information found', 'Jinjie Duan', '1', 'Kristian Wejse Sanggaard', '2', '3', 'Leif Schauser', '4', 'Sanne Enok Lauridsen', '5', 'Jan J Enghild', '2', '3', 'Mikkel Heide Schierup', '1', '5', 'Tobias Wang', '5'], 'Publication Name': '© The Authors 2017. Published by Oxford University Press.', 'ISSN': \"['No information found']\", 'Cited count': \"['No information found']\", 'Affiliation': '1 Bioinformatics Research Center, Aarhus University, C.F. Moellers Alle 8, Aarhus C, Denmark.', 'Type': \"['article']\", 'Published date': ['No information found'], 'Abstract': 'Exceptional and extreme feeding behaviour makes the Burmese python (Python bivittatus) an interesting model to study physiological remodelling and metabolic adaptation in response to refeeding after prolonged starvation. In this study, we used transcriptome sequencing of 5 visceral organs during fasting as well as 24 hours and 48 hours after ingestion of a large meal to unravel the postprandial changes in Burmese pythons. We first used the pooled data to perform a de novo assembly of the transcriptome and supplemented this with a proteomic survey of enzymes in the plasma and gastric fluid. We constructed a high-quality transcriptome with 34 423 transcripts, of which 19 713 (57%) were annotated. Among highly expressed genes (fragments per kilo base per million sequenced reads > 100 in 1 tissue), we found that the transition from fasting to digestion was associated with differential expression of 43 genes in the heart, 206 genes in the liver, 114 genes in the stomach, 89 genes in the pancreas, and 158 genes in the intestine. We interrogated the function of these genes to test previous hypotheses on the response to feeding. We also used the transcriptome to identify 314 secreted proteins in the gastric fluid of the python. Digestion was associated with an upregulation of genes related to metabolic processes, and translational changes therefore appear to support the postprandial rise in metabolism. We identify stomach-related proteins from a digesting individual and demonstrate that the sensitivity of modern liquid chromatography/tandem mass spectrometry equipment allows the identification of gastric juice proteins that are present during digestion.'}]}}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logger\n",
    "sys.path.insert(1,os.getcwd())\n",
    "#sys.path.insert(1,'Users/chandrayogyadav/Desktop/getArticleTool/')\n",
    "from GoogleScholar import search_googleScholar\n",
    "from MSAcademic import search_msAcademic\n",
    "from CORE import search_core\n",
    "from pubMed import search_pubMed\n",
    "from ACMLib import search_acmlibrary\n",
    "from PLOSOne import search_PlosOne\n",
    "from Academia import search_academia\n",
    "from ElseScopus import search_scopus\n",
    "from Springer import search_springer\n",
    "from SciDirect import search_sciDirect\n",
    "\n",
    "\n",
    "# ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### setting output display options\n",
    "pd.set_option('display.width', 400)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# desktop user-agent\n",
    "USER_AGENT = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Chrome/80.0.3987.149 Safari/601.3.9\"\n",
    "\n",
    "# mobile user-agent\n",
    "MOBILE_USER_AGENT = \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"\n",
    "\n",
    "# creating header for request\n",
    "headers = {'User-Agent': USER_AGENT}\n",
    "\n",
    "print(\"Path at terminal when executing this file\")\n",
    "print(os.getcwd() + \"\\n\")\n",
    "\n",
    "curr_path=os.getcwd()\n",
    "### read config json file for API keys\n",
    "with open(\"config.json\") as json_data_file:\n",
    "    data = json.load(json_data_file)\n",
    "\n",
    "#scraper api key\n",
    "scrpr_api= data['apikeys']['scrpr_api']\n",
    "\n",
    "# Microsoft API Key\n",
    "ms_api = data['apikeys']['ms_api']\n",
    "\n",
    "# CORE API key\n",
    "core_api = data['apikeys']['core_api']\n",
    "\n",
    "# Scopus API Key\n",
    "scp_api = data['apikeys']['scp_api']\n",
    "\n",
    "# ScienceDirect API Keys\n",
    "# 1. Search All API Key\n",
    "sd1_api = data['apikeys']['sd1_api']\n",
    "# 2. Search Article attributes API Key\n",
    "sd2_api = data['apikeys']['sd2_api']\n",
    "\n",
    "# Springer API KEY\n",
    "spr_api = data['apikeys']['spr_api']\n",
    "\n",
    "#proxy value\n",
    "#proxy_val = data['apikeys']['proxy_val']\n",
    "\n",
    "## inital variables\n",
    "search_query = ''\n",
    "_title = False\n",
    "_keyword = False\n",
    "_abstract = False\n",
    "_records = str(10)\n",
    "_from_yr=''\n",
    "_to_yr_=''\n",
    "_gs_pages=''\n",
    "# search keywords\n",
    "# search_query = \"Python\"\n",
    "records = str(0)\n",
    "_search_yr =''\n",
    "# Input var 1- Choose search engine option\n",
    "print(\"Enter search engine number to lookup your article from list, input multiple numbers with space only:\\n 0 ALL, 1 Google Scholar, 2 MS Academic, 3 CORE, 4 PubMed, 5 ACM Library, 6 PLOS ONE, 7 Academia, 8 Elsevier Scopus, 9 Springer, 10 Science Direct\")\n",
    "x = list(map(int, input(\"Enter a Search Engine value: \").split()))\n",
    "if len(x)==0:\n",
    "    print('Select search engine!')\n",
    "    quit()\n",
    "\n",
    "# Input var 2- Save output to a path option\n",
    "print(\"Enter the path to save the JSON output file or enter to save on default location:\\n E.g. (/Users/computername/Desktop/) \")\n",
    "output_path = input(\"Path:\")\n",
    "\n",
    "# Input var 3- Dataframe output option\n",
    "out=input(\"Do you also want Excel output? Y/N :\").lower()\n",
    "\n",
    "# Input var 4- Dataframe output option\n",
    "logging_flag = input(\"Do you also want Logging? Y/N :\").lower()\n",
    "\n",
    "# Input var 5- No of records option\n",
    "rec = str(input(\"Enter No of records to search(Minimum 10 or press enter):\")).split()\n",
    "if len(rec) != 0:\n",
    "    records = rec[0]\n",
    "    _gs_pages=records\n",
    "    _acm_pages = records\n",
    "    _els_pages = records\n",
    "\n",
    "else:\n",
    "    records = str(10)\n",
    "    _gs_pages=0\n",
    "    _acm_pages = 0\n",
    "    _els_pages = 0\n",
    "\n",
    "# Input 6- Search year parameter option\n",
    "year1=str(input(\"Enter the FROM year (optional):\")).strip()\n",
    "if len(year1)!=0:\n",
    "    _from_yr=year1\n",
    "else:\n",
    "    _from_yr=''\n",
    "\n",
    "# Input 7- Search year parameter option\n",
    "year2=str(input(\"Enter the TO year (optional):\")).strip()\n",
    "if len(year2)!=0:\n",
    "    _to_yr_=year2\n",
    "else:\n",
    "    _to_yr_=''\n",
    "\n",
    "\n",
    "# Input 8,9,10 - Title, Keyword, Abstract search options\n",
    "print('Choose either Title, Keyword, or Abstract Info as options to search:')\n",
    "param1 = str(input(\"Enter Keyword to search (if not then press enter to go to next option):\")).capitalize().strip()\n",
    "NoneType = type(None)\n",
    "if param1 != '':\n",
    "    _keyword = True\n",
    "   #search_query = str(param1).replace('\"', '')\n",
    "    search_query= param1\n",
    "else:\n",
    "    param2 = str(input(\"Enter Abstract info to search (if not then press enter to go to next option):\")).capitalize().strip()\n",
    "    if param2 != '':\n",
    "        _abstract = True\n",
    "        search_query = str(param2).replace('\"', '')\n",
    "    else:\n",
    "        param3 = str(input(\"Enter Full Title to search:\")).capitalize().strip()\n",
    "        if param3 != '':\n",
    "            _title = True\n",
    "            _param = str(param3).replace('\"', '')\n",
    "            search_query = urllib.parse.quote_plus(_param)\n",
    "        else:\n",
    "            print(\"Please provide some input!\")\n",
    "\n",
    "# create dictionary object for output\n",
    "data = []\n",
    "\n",
    "\n",
    "# function for search engines\n",
    "def search_engines(query, x):\n",
    "    # Search all engines\n",
    "        try:\n",
    "            check_DateParams(_from_yr, _to_yr_)\n",
    "            ## uncomment the search engine baesd your requiremnt\n",
    "            if len(x)!=0:\n",
    "                ### call the search fucntion for all\n",
    "                try:\n",
    "                     if 0 in x:\n",
    "\n",
    "                        search_allengines(search_query)\n",
    "                except Exception as e:  # raise e\n",
    "                    pass  # print('error:', e)\n",
    "\n",
    "                ###---Engines for Title, Keyword and Abstract---###\n",
    "                try:\n",
    "                    if 1 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_googleScholar(query,headers,_gs_pages,records,_title,_keyword,_abstract, scrpr_api,_from_yr,_to_yr_,logging_flag, data)   # done\n",
    "                except Exception as e:  # raise e\n",
    "                    pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"Google Scholar\", logging_flag, filename, line_number)\n",
    "                try:\n",
    "                   if 2 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_msAcademic(query,headers, _pages,records,_title,_keyword,_abstract,ms_api,_from_yr,_to_yr_,logging_flag, data)  # done\n",
    "                except Exception as e:  # raise e\n",
    "                    #pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"MS Academic\", logging_flag, filename, line_number)\n",
    "                try:\n",
    "                    if 3 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_core(query,headers, _pages,records,_title,_keyword,_abstract,core_api,_search_yr,logging_flag,  data)  # done\n",
    "                except Exception as e:  # raise e\n",
    "                    pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"CORE Engine\", logging_flag, filename, line_number)\n",
    "                try:\n",
    "                    if 4 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_pubMed(query,headers, _pages,_title,_keyword,_abstract,_from_yr,_to_yr_, logging_flag, data)  # done\n",
    "                except Exception as e:  # raise e\n",
    "                    #pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"PubMed Engine\", logging_flag, filename, line_number)\n",
    "                try:\n",
    "                    if 5 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_acmlibrary(query,headers, _acm_pages,records,_title,_keyword,_abstract,_from_yr,_to_yr_,logging_flag, data)  # done\n",
    "                except Exception as e:  # raise e\n",
    "                     pass\n",
    "                     exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                     filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                     line_number = exception_traceback.tb_lineno\n",
    "                     logger.writeError(e, None, \"ACM Library Engine\", logging_flag, filename, line_number)\n",
    "\n",
    "                ##---Engines only for Keyword and Abstract---###\n",
    "                try:\n",
    "                    if 6 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_PlosOne(query,headers, _pages,records,_title,_keyword,_abstract,_from_yr,_to_yr_,logging_flag, data)  # done\n",
    "                except Exception as e:  # raise e\n",
    "                    #pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"PLOSE One Engine\", logging_flag, filename, line_number)\n",
    "                try:\n",
    "                    if 7 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_academia(query,headers, _pages,records,_title,_keyword,_abstract,_search_yr, logging_flag, data)\n",
    "                except Exception as e:  # raise e\n",
    "                    pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"Academia Engine\", logging_flag, filename, line_number)\n",
    "                try:\n",
    "                    if 8 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_scopus(query,headers, _els_pages,records,_title,_keyword,_abstract,scp_api,_from_yr,_to_yr_,logging_flag, data)  # done\n",
    "                except Exception as e:  # raise e\n",
    "                    pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"Elsevier Scopus\", logging_flag, filename, line_number)\n",
    "\n",
    "                try:\n",
    "                    if 9 in x:\n",
    "                       _pages = pagination(records)\n",
    "                       search_springer(query,headers, _pages,records,_title,_keyword,_abstract,spr_api,_search_yr,logging_flag, data)  # done\n",
    "                except Exception as e:  # raise e\n",
    "                    pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"Springer\", logging_flag, filename, line_number)\n",
    "\n",
    "                try:\n",
    "                    if 10 in x:\n",
    "                      _pages = pagination(records)\n",
    "                      search_sciDirect(query,headers, _pages,records,_title,_keyword,_abstract,sd1_api, sd2_api,_from_yr,_to_yr_,logging_flag, data)\n",
    "                except Exception as e:  # raise e\n",
    "                    pass\n",
    "                    exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                    filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                    line_number = exception_traceback.tb_lineno\n",
    "                    logger.writeError(e, None, \"Science Direct\", logging_flag, filename, line_number)\n",
    "\n",
    "            else:\n",
    "                print('Select search engine!')\n",
    "                exit\n",
    "\n",
    "        except Exception as e:  # raise e\n",
    "            pass  # print('error:', e)\n",
    "\n",
    "# function for search engines\n",
    "def search_allengines(query):\n",
    "    # Search all engines\n",
    "        try:\n",
    "            try:\n",
    "            ###---Engines for Title, Keyword and Abstract---###\n",
    "                    _pages = pagination(records)\n",
    "                    search_googleScholar(query, headers, _pages, records, _title, _keyword, _abstract, scrpr_api,_from_yr,_to_yr_,logging_flag, data)  # done\n",
    "            except Exception as e:  # raise e\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "                logger.writeError(e, None, \"Google Scholar\", logging_flag, filename, line_number)\n",
    "                pass  # print('error:', e)\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_msAcademic(query, headers, _pages, records, _title, _keyword, _abstract, ms_api,_from_yr,_to_yr_,logging_flag, data)  # done\n",
    "            except Exception as e:  # raise e\n",
    "                 pass\n",
    "                 exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                 filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                 line_number = exception_traceback.tb_lineno\n",
    "                 logger.writeError(e, None, \"MS Academic Engine\", logging_flag, filename, line_number)\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_core(query, headers, _pages, records, _title, _keyword, _abstract, core_api,_search_yr,logging_flag, data)  # done\n",
    "            except Exception as e:  # raise e\n",
    "                pass\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "                logger.writeError(e, None, \"CORE Engine\", logging_flag, filename, line_number)\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_pubMed(query, headers, _pages, _title, _keyword, _abstract, _from_yr,_to_yr_,logging_flag, data)  # done\n",
    "            except Exception as e:  # raise e\n",
    "                 pass\n",
    "                 exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                 filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                 line_number = exception_traceback.tb_lineno\n",
    "                 logger.writeError(e, None, \"PubMed Engine\", logging_flag, filename, line_number)\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_acmlibrary(query, headers, _acm_pages, records, _title, _keyword, _abstract,_from_yr,_to_yr_,logging_flag, data)  # done\n",
    "            except Exception as e:  # raise e\n",
    "                pass\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "                logger.writeError(e, None, \"ACM Library\", logging_flag, filename, line_number)\n",
    "\n",
    "            ##---Engines only for Keyword and Abstract---###\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_PlosOne(query, headers, _pages, records, _title, _keyword, _abstract, _from_yr,_to_yr_,logging_flag, data)  # done\n",
    "            except Exception as e:  # raise e\n",
    "                pass\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "                logger.writeError(e, None, \"PLOS One Engine\", logging_flag, filename, line_number)\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_academia(query, headers, _pages, records, _title, _keyword, _abstract,_search_yr,logging_flag, data)\n",
    "            except Exception as e:  # raise e\n",
    "                pass\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "                logger.writeError(e, None, \"Academia Engine\", logging_flag, filename, line_number)\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_scopus(query, headers, _els_pages, records, _title, _keyword, _abstract, scp_api,_from_yr,_to_yr_, logging_flag, data)  # done\n",
    "            except Exception as e:  # raise e\n",
    "                pass  # print('error:', e)\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "                logger.writeError(e, None, \"Elsevier Scopus\", logging_flag, filename, line_number)\n",
    "\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_springer(query, headers, _pages, records, _title, _keyword, _abstract, spr_api,_search_yr,logging_flag, data)  # done\n",
    "            except Exception as e:  # raise e\n",
    "                pass\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "                logger.writeError(e, None, \"Springer Engine\", logging_flag, filename, line_number)\n",
    "\n",
    "            try:\n",
    "                    _pages = pagination(records)\n",
    "                    search_sciDirect(query, headers, _pages, records, _title, _keyword, _abstract, sd1_api, sd2_api,_from_yr,_to_yr_,logging_flag, data)\n",
    "            except Exception as e:  # raise e\n",
    "                pass\n",
    "                exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "                filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "                line_number = exception_traceback.tb_lineno\n",
    "                logger.writeError(e, None, \"Science Direct\", logging_flag, filename, line_number)\n",
    "\n",
    "        except Exception as e:  # raise e\n",
    "            pass\n",
    "            exception_type, exception_object, exception_traceback = sys.exc_info()\n",
    "            filename = exception_traceback.tb_frame.f_code.co_filename\n",
    "            line_number = exception_traceback.tb_lineno\n",
    "            logger.writeError(e, None, \"Search Exception :\", logging_flag, filename, line_number)\n",
    "\n",
    "\n",
    "### method to find no of pages for webscrapping engines\n",
    "def pagination(records):\n",
    "    page = 1\n",
    "    def_record = 10\n",
    "    if (records == 10):\n",
    "        page = 1\n",
    "    else:\n",
    "        page = round((float(records) / def_record))\n",
    "    return page\n",
    "\n",
    "def check_DateParams(_from, _to):\n",
    "    if(len(_from_yr) and not(_to)):\n",
    "        print(\"Search years options either entered wrong or left blank!\")\n",
    "        quit()\n",
    "    elif(not(_from_yr) and len(_to)):\n",
    "        print(\"Search years options either wrong or left blank!\")\n",
    "        quit()\n",
    "    ###------Main Call to search-------####\n",
    "### Call search engines\n",
    "search_engines(search_query,x)\n",
    "# print the dict output\n",
    "print(data)\n",
    "\n",
    "\n",
    "### Function to save JSON output to a file\n",
    "def save_output(output):\n",
    "    if output_path:\n",
    "        #writepath = \"/Users/chandrayogyadav/Desktop/data.json\"  ### define path to you desired location for file\n",
    "        writepath = output_path\n",
    "        mode = 'a' if os.path.exists(writepath) else 'w+'\n",
    "        with open(writepath+\"/data.json\", mode) as f:\n",
    "            f.close()\n",
    "            f.write(output)\n",
    "    else:\n",
    "        try:\n",
    "            if os.path.exists(\"data.json\"):\n",
    "                os.remove(\"data.json\")\n",
    "                f = open(\"data.json\", \"x\")\n",
    "                f.write(output)\n",
    "                f.close()\n",
    "            else:\n",
    "                f = open(\"data.json\", \"x\")\n",
    "                f.write(output)\n",
    "                f.close()\n",
    "        except Exception as e:  # raise e\n",
    "            #pass\n",
    "             print(\"Output file:\", e)\n",
    "\n",
    "# check if the output received or not then create further dataframe\n",
    "if bool(data):\n",
    "    # convert dict object into JSON:\n",
    "    json_output = json.dumps(data, indent=2, sort_keys=True)\n",
    "\n",
    "    # print(json_output)\n",
    "    save_output(json_output)\n",
    "    if out == 'y':\n",
    "        #convert json into datafrme\n",
    "        df = pd.json_normalize(data)\n",
    "\n",
    "        #####-----creating final output------#####\n",
    "        # drop nested columns and keep 1st attribute\n",
    "        df.drop([\"entities.items\"], axis=1, inplace=True)\n",
    "\n",
    "        # create required temp objets\n",
    "        d1 = pd.DataFrame([])\n",
    "        result = pd.DataFrame([])\n",
    "\n",
    "        # split nested attributes into separate columns and stored output in a temp object d1\n",
    "        i = 0\n",
    "        for i in range(0, len(data)):\n",
    "            d = pd.json_normalize(data[i]['entities']['items'])\n",
    "            d1 = d1.append(d, True)\n",
    "\n",
    "            # concatenate both dataframes into one\n",
    "            result = pd.concat([df, d1], axis=1)\n",
    "            # print('Output in Dataframe format with columns ')\n",
    "            # print(result)\n",
    "        if os.path.exists(\"search_results.xlsx\"):\n",
    "            # save final output to csv\n",
    "            result.to_excel('search_results.xlsx', index=False)\n",
    "            print('Spreadsheet saved.')\n",
    "        else:\n",
    "            result.to_excel('search_results.xlsx', index=False)\n",
    "            print('Spreadsheet saved.')\n",
    "            # print(result)\n",
    "    else:\n",
    "        exit\n",
    "else:\n",
    "    print(\"No record found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-buyer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
